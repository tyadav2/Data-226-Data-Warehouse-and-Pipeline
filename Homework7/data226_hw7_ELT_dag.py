# -*- coding: utf-8 -*-
"""Data226_HW7_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P4VJkT4lJ0kn3DqC7_eBusz6NIVPKbNi
"""

from airflow.decorators import task
from airflow import DAG
from airflow.models import Variable
from airflow.operators.python import get_current_context
from airflow.providers.snowflake.hooks.snowflake import SnowflakeHook

from datetime import datetime
from datetime import timedelta
import logging
import snowflake.connector

"""
This pipeline assumes that there are two other tables in your snowflake DB
 - user_session_channel
 - session_timestamp

With regard to how to set up these two tables, please refer to this README file:
 - https://github.com/keeyong/sjsu-data226/blob/main/week9/How-to-setup-ETL-tables-for-ELT.md
"""

def return_snowflake_conn():

    # Initialize the SnowflakeHook
    hook = SnowflakeHook(snowflake_conn_id='snowflake_conn')

    # Execute the query and fetch results
    conn = hook.get_conn()
    return conn.cursor()


@task
def run_ctas(table, select_sql, primary_key=None):

    logging.info(table)
    logging.info(select_sql)

    cur = return_snowflake_conn()

    try:
        cur.execute("BEGIN;")
        sql = f"CREATE OR REPLACE TABLE {table} AS {select_sql}"
        logging.info(sql)
        cur.execute(sql)

        # do primary key uniqueness check
        if primary_key is not None:
            sql = f"SELECT {primary_key}, COUNT(1) AS cnt FROM {table} GROUP BY 1 ORDER BY 2 DESC LIMIT 1"
            print(sql)
            cur.execute(sql)
            result = cur.fetchone()
            print(result, result[1])
            if int(result[1]) > 1:
                print("!!!!!!!!!!!!!!")
                raise Exception(f"Primary key uniqueness failed: {result}")

        # duplicate check
        sql2 = f"SELECT COUNT(1) AS cnt FROM {table}"
        sql3 = f"SELECT COUNT(DISTINCT {primary_key}) AS cnt2 FROM {table}"

        cur.execute(sql2)
        total_count = cur.fetchone()[0]  # Store result of total count

        cur.execute(sql3)
        distinct_count = cur.fetchone()[0]  # Store result of distinct count

        # Compare the total and distinct counts
        if total_count != distinct_count:
            raise Exception(f"Duplicate check failed: Total {total_count}, Distinct {distinct_count}")

        cur.execute("COMMIT;")
    except Exception as e:
        cur.execute("ROLLBACK")
        logging.error('Failed to sql. Completed ROLLBACK!')
        raise


with DAG(
    dag_id='BuildELT_CTAS_HW8',
    start_date=datetime(2024, 10, 23),
    catchup=False,
    tags=['ELT', 'HW8'],
    schedule='45 2 * * *'
) as dag:

    table = "data226.analytics.session_summary"
    select_sql = """SELECT u.*, s.ts
    FROM data226.raw_data.user_session_channel u
    JOIN data226.raw_data.session_timestamp s ON u.sessionId=s.sessionId
    """

    run_ctas(table, select_sql, primary_key='sessionId')